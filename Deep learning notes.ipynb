{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Review backward and forward propagation - in the process\n",
    "- Look into keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Supervised learning__ occurs when your deep learning model learns and makes inferences from data that has already been labeled \n",
    "\n",
    "__Unsupervised learning__ occurs when the model learns and makes inferences from unlabeled data \n",
    "\n",
    "__Artificial neural networks__ are deep learning models that are based on the structure of the brain's neural networks. Same as neural net, net, and model\n",
    "\n",
    "An __activation function__ of a neuron defines the output of that neuron given a set of inputs\n",
    "\n",
    "__Relu__ - rectified linear unit ($\\max(0,x)$)\n",
    "\n",
    "__Sigmoid activation function__ - $\\cfrac{1}{1 + e^{-x}}$\n",
    "\n",
    "__Learning__ is about finding the right weights and biases\n",
    "\n",
    "__Cost(loss) function__ - function that maps an event or values of one or more variables onto a real number, representing from \"cost\" associated with the event. We are seeking to minimize the cost function\n",
    "\n",
    "__Gradient descent__ - first-order iterative optimization algorithm for finding a local minimum of a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neurons are organized in layers\n",
    "\t- Input layer\n",
    "\t- Hidden layer\n",
    "\t- Output layer\n",
    "Each node is a neuron\n",
    "Each vertical line is a layer\n",
    "The hidden layers are between input and output layers\n",
    "\n",
    "How do you build one?\n",
    "\n",
    "With Keras!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([Dense(32, input_shape = (10, ), activation = \"relu\"), \n",
    "                    Dense(2, activation = \"softmax\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dense is the most basic type of layer. It connects each input to each  output. The first parameter is the number of nodes in the layer.\n",
    "Some commonly used layers:\n",
    "- Dense (or fully connected) - connects each input to each output\n",
    "- Concolutional layers - image data\n",
    "- Pooling layers\n",
    "- Recurrent layers - time series data\n",
    "- Normalization layers\n",
    "- Many others\n",
    "\n",
    "Each connection transfers the output from the previous layer as input to the receiving unit. Each connection has assigned weight. The output is the weighted sum of the inputs. \n",
    "\n",
    "Output - the classification categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "model = Sequential([ Dense(5, input_shape = (3,), activation = \"relu\"), \n",
    "                   Dense(2, activation = \"softmax\"),\n",
    "                   ])\n",
    "# Note that the input shape for layers past the first one is not required\n",
    "# because "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the activation function, the neuron is either fired or not fired. Where 0 if for not firing while 1 is for firing.\n",
    "\n",
    "However, an activation function is not always returning a value between 0 and 1. For example, the most widely used activation function - relu. The main idea is that the more positive neuron, the more active it is. \n",
    "\n",
    "Another way to define a sequential model is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(5, input_shape = (3, )))\n",
    "model.add(Activation(\"relu\"))\n",
    "# Here, the activation layer is added separately from the Desnse layer.\n",
    "# The process is the same though"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  The initial bias and weights are randomized. Then, the cost function is defined to tell the computer how far the output is from the expected one. Then, the cost function is optimized. \n",
    " \n",
    " For example, we can have a sum of the squares of differences between the expected and the observed results. \n",
    " \n",
    " !! REMEMBER !!\n",
    " \n",
    " The gradient is pointing in the direction of largest increase. Hence, as we are looking to minimize the cost function, we will be adjusting the parameters in the direction opposite of the gradient. This process is called gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
